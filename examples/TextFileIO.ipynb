{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Filesystem I/O in Python\n",
    "\n",
    "Often, the text we want to work with comes in a raw .txt format. Take for example the [Cornell movie review dataset](http://www.cs.cornell.edu/people/pabo/movie-review-data/review_polarity.tar.gz).\n",
    "\n",
    "We can download the above archive, extract it and read a single review very easily."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"Datasets/review_polarity/txt_sentoken/neg/cv001_19502.txt\") as f:\n",
    "    text = f.read()\n",
    "\n",
    "print(text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Reading a whole file in a single operation may not be practical if the file is large and you wish to operate on it iteratively (i.e. line by line). \n",
    "\n",
    "Python provides a readlines() function which reads text files line-by-line (i.e. it uses yield for each line)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"Datasets/review_polarity/txt_sentoken/neg/cv001_19502.txt\") as f:\n",
    "    for line in f.readlines():\n",
    "        print(line)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What about reading the files in a whole directory or subdirectory structure to process? We don't want to be typing in all the file names.\n",
    "\n",
    "That's where the `os` module and specifically `os.walk` function can help. \n",
    "\n",
    "`os.walk` recursively navigates a directory tree and inspect all files within that structure. All we need is to specify which directory to start."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "for root, dirs, files in os.walk(\"Datasets/review_polarity/\"):\n",
    "    # this outer loop iterates over each subdirectory - \n",
    "    # and updates 'root' with the current directory being nagivated.\n",
    "    print(\"\\n--> Current root: \", root)\n",
    "    \n",
    "    #inside each subdirectory we get lists of sub-subdirectories (dirs that reside in the current root)\n",
    "    for directory in dirs:\n",
    "        print (\"DIR  \", directory)\n",
    "        \n",
    "    #we also get a list of files in each sub-directory too (files inside the current root dir)\n",
    "    for file in files:\n",
    "        print(\"FILE \", file)\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What if we are only interested in a specific set of files or directories? We can filter the filenames by matching them with rules.\n",
    "\n",
    "Here we assume that we only want text files."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for root, dirs, files in os.walk(\"Datasets/review_polarity/\"):    \n",
    "    for file in files:\n",
    "        if file.endswith(\".txt\"):\n",
    "            print(file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To get the pull path to a file, we can use `os.path.join`, which joins file paths in an OS independent way - it takes care of where to put slash/ back slash characters for you. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for root, dirs, files in os.walk(\"Datasets/review_polarity/\"):    \n",
    "    for file in files:\n",
    "        if file.endswith(\".txt\"):\n",
    "            # current value of `root` holds the full directory path to the file\n",
    "            print(\"\\nRoot: \", root)\n",
    "            print(os.path.join(root,file))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now lets find out how many lines there are in total across all the reviews."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "linecount = 0\n",
    "\n",
    "for root, dirs, files in os.walk(\"Datasets/review_polarity/\"):    \n",
    "    for file in files:\n",
    "        if file.endswith(\".txt\"):\n",
    "            with open(os.path.join(root,file)) as f:\n",
    "                for line in f.readlines():\n",
    "                    linecount += 1\n",
    "                    \n",
    "print(\"Total lines in all txt files\", linecount)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Writing a file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('Datasets/review_polarity/fake.txt', 'w') as file:  \n",
    "    file.write('Fake review!')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conclusion\n",
    "\n",
    "We are now able to process directory trees containing multiple files of text data and filter those files. We can read in a file in one chunk or incrementally line-by-line."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
