{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Assignment Two:  Sentiment Classification\n",
    "\n",
    "For this exercise you will be using the \"SemEval 2017 task 4\" corpus provided on the module website, available through the following link: https://warwick.ac.uk/fac/sci/dcs/teaching/material/cs918/semeval-tweets.tar.bz2 You will focus particularly on Subtask A, i.e. classifying the overall sentiment of a tweet as positive, negative or neutral.\n",
    "\n",
    "You are requested to produce a Jupyter notebook for the coursework submission. The input to your program is the SemEval data downloaded. Note that TAs need to run your program on their own machine by using the original SemEval data. As such, don’t submit a Python program that takes as input some preprocessed files."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Define Utility Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections.abc import Generator\n",
    "from os import path, getcwd, listdir, makedirs\n",
    "\n",
    "\n",
    "def read_file_lines_from(file_path: str, /) -> Generator[str, None, None]:\n",
    "    \"\"\"\n",
    "    Read lines from a file and yield each line as a string.\n",
    "    The path to the file is relative to the current working directory.\n",
    "\n",
    "    Args:\n",
    "        file_path (str): The path to the file to be read.\n",
    "\n",
    "    Yields:\n",
    "        str: Each line of the file, stripped of leading and trailing whitespace.\n",
    "    \"\"\"\n",
    "    full_path = path.join(getcwd(), file_path)\n",
    "    buffer_size = 1024 * 1024\n",
    "    with open(full_path, 'r', buffering=buffer_size, encoding='utf8') as file:\n",
    "        for line in file:\n",
    "            yield line.strip()\n",
    "\n",
    "\n",
    "def ls(dir_path: str, /) -> tuple[str, ...]:\n",
    "    \"\"\"\n",
    "    List all files and directories in the specified directory.\n",
    "    \"\"\"\n",
    "    full_path = path.join(getcwd(), dir_path)\n",
    "    return tuple(listdir(full_path))\n",
    "\n",
    "\n",
    "def mkdir(dir_path: str, /) -> None:\n",
    "    \"\"\"\n",
    "    Create a directory.\n",
    "    \"\"\"\n",
    "    full_path = path.join(getcwd(), dir_path)\n",
    "    if not path.exists(full_path):\n",
    "        makedirs(full_path)\n",
    "\n",
    "\n",
    "def path_exists(location: str, /) -> bool:\n",
    "    \"\"\"\n",
    "    Check if the specified path exists.\n",
    "    \"\"\"\n",
    "    full_path = path.join(getcwd(), location)\n",
    "    return path.exists(full_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections.abc import Callable\n",
    "from threading import Thread, Lock\n",
    "from typing import final\n",
    "\n",
    "\n",
    "@final\n",
    "class BackgroundTask:\n",
    "    \"\"\"\n",
    "    Represents a background task that can be executed concurrently.\n",
    "\n",
    "    Args:\n",
    "        task (Callable): The function or method to be executed as a background task.\n",
    "        *args: Variable length argument list to be passed to the task.\n",
    "        **kwargs: Arbitrary keyword arguments to be passed to the task.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, task: Callable[..., None], *args, **kwargs):\n",
    "        self.__task = Thread(\n",
    "            target=task,\n",
    "            args=args,\n",
    "            kwargs=kwargs,\n",
    "            daemon=True\n",
    "        )\n",
    "        with Lock():\n",
    "            self.__task.start()\n",
    "\n",
    "    def wait(self) -> None:\n",
    "        \"\"\"\n",
    "        Waits for the background task to complete.\n",
    "        \"\"\"\n",
    "        return self.__task.join()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def unzip_file_to(file_path: str, /, destination: str) -> None:\n",
    "    \"\"\"\n",
    "    Unzip a file to a specified destination.\n",
    "\n",
    "    Args:\n",
    "        file_path (str): The path to the file to be unzipped.\n",
    "        destination (str): The path to the directory where the file will be unzipped.\n",
    "    \"\"\"\n",
    "    import zipfile\n",
    "    full_path = path.join(getcwd(), file_path)\n",
    "    with zipfile.ZipFile(full_path, 'r') as zip_ref:\n",
    "        zip_ref.extractall(destination)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Any, Final, Optional\n",
    "from shelve import open as shelve_open\n",
    "\n",
    "\n",
    "class GlobalCache:\n",
    "    \"\"\"\n",
    "    A simple global cache for storing data in memory.\n",
    "    \"\"\"\n",
    "\n",
    "    __runtime_cache: Final[dict[str, Any]] = {}\n",
    "    __cache_file_name: Final[str] = 'cache'\n",
    "\n",
    "    def put(self, key: str, value: object, /) -> None:\n",
    "        \"\"\"\n",
    "        Put a value into the cache.\n",
    "\n",
    "        Args:\n",
    "            key (str): The key to be used to store the value.\n",
    "            value (object): The value to be stored.\n",
    "        \"\"\"\n",
    "\n",
    "        self.__runtime_cache[key] = value\n",
    "        with shelve_open(self.__cache_file_name, 'c') as cache:\n",
    "            cache[key] = value\n",
    "\n",
    "    def get(self, key: str, /) -> Optional[Any]:\n",
    "        \"\"\"\n",
    "        Get a value from the cache.\n",
    "\n",
    "        Args:\n",
    "            key (str): The key to be used to retrieve the value.\n",
    "\n",
    "        Returns:\n",
    "            object: The value stored in the cache.\n",
    "        \"\"\"\n",
    "\n",
    "        if key in self.__runtime_cache:\n",
    "            return self.__runtime_cache[key]\n",
    "\n",
    "        with shelve_open(self.__cache_file_name, 'c') as cache:\n",
    "            return cache.get(key)\n",
    "\n",
    "    def remove(self, key: str, /) -> None:\n",
    "        \"\"\"\n",
    "        Remove a value from the cache.\n",
    "\n",
    "        Args:\n",
    "            key (str): The key to be used to remove the value.\n",
    "        \"\"\"\n",
    "\n",
    "        self.__runtime_cache.pop(key, None)\n",
    "        with shelve_open(self.__cache_file_name, 'c') as cache:\n",
    "            del cache[key]\n",
    "\n",
    "    def clear(self) -> None:\n",
    "        \"\"\"\n",
    "        Clear the cache.\n",
    "        \"\"\"\n",
    "\n",
    "        self.__runtime_cache.clear()\n",
    "        with shelve_open(self.__cache_file_name, 'c') as cache:\n",
    "            cache.clear()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Package imports for Application logic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import csv\n",
    "import regex as re\n",
    "import contractions\n",
    "import torch\n",
    "\n",
    "from os import cpu_count\n",
    "from typing import Final, final\n",
    "from types import NoneType\n",
    "from string import punctuation, digits\n",
    "from functools import lru_cache\n",
    "from concurrent.futures import ProcessPoolExecutor, as_completed\n",
    "from enum import Enum\n",
    "from collections import defaultdict, Counter, OrderedDict\n",
    "from collections.abc import Sequence\n",
    "from copy import copy\n",
    "from huggingface_hub import hf_hub_download\n",
    "from emoji import demojize\n",
    "from nltk.downloader import download as nltk_download\n",
    "from nltk.corpus import stopwords, wordnet\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from nltk.tokenize import TweetTokenizer\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "from transformers import BertTokenizer, BertModel, BertConfig, get_linear_schedule_with_warmup\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Define global instances"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_base_path: Final[str] = 'data'\n",
    "glove_data_dir: Final[str] = f\"{dataset_base_path}/glove\"\n",
    "target_glove_file_name: Final[str] = \"glove.6B.100d.txt\"\n",
    "target_bert_model_name: Final[str] = 'bert-base-multilingual-uncased'\n",
    "target_mixtral_model_name: Final[str] = 'mistralai/Mistral-7B-Instruct-v0.2'\n",
    "\n",
    "# names of the test set files\n",
    "test_set_names: Final[tuple[str, ...]] = (\n",
    "    'twitter-test1.txt',\n",
    "    'twitter-test2.txt',\n",
    "    'twitter-test3.txt',\n",
    ")\n",
    "training_data_file_name: Final[str] = 'twitter-training-data.txt'\n",
    "devlopment_data_file_name: Final[str] = 'twitter-dev-data.txt'\n",
    "\n",
    "\n",
    "@final\n",
    "class Sentiment(Enum):\n",
    "    \"\"\"\n",
    "    An enumeration of the three possible sentiment values.\n",
    "    \"\"\"\n",
    "    positive = 2\n",
    "    negative = 1\n",
    "    neutral = 0\n",
    "\n",
    "    @classmethod\n",
    "    @lru_cache\n",
    "    def gts(cls) -> tuple[str, ...]:\n",
    "        return tuple(cls.__members__.keys())\n",
    "\n",
    "\n",
    "global_cache = GlobalCache()\n",
    "\n",
    "TweetID = str\n",
    "ShouldMarkedAsBackground = NoneType"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Define data retrieval functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "@lru_cache(typed=True)\n",
    "def get_tweets_from(file_name_: str, /) -> tuple[dict[TweetID, str], tuple[Sentiment, ...]]:\n",
    "    \"\"\"\n",
    "    Read tweets from a file and return dictionaries containing tweet IDs, contents, and sentiments.\n",
    "\n",
    "    Parameters:\n",
    "    - file_name_ (str): The name of the file to read tweets from.\n",
    "\n",
    "    Returns:\n",
    "    - A tuple containing two dictionaries:\n",
    "        - id_gts (dict[TweetID, str]): A dictionary mapping tweet IDs to their contents.\n",
    "        - id_sentiments (dict[TweetID, Sentiment]): A dictionary mapping tweet IDs to their sentiments.\n",
    "    \"\"\"\n",
    "    id_gts: OrderedDict[TweetID, str] = OrderedDict()\n",
    "    sentiments: list[Sentiment] = []\n",
    "    lines = read_file_lines_from(f'{dataset_base_path}/{file_name_}')\n",
    "    for line in lines:\n",
    "        fields = line.split('\\t')\n",
    "        tweet_id = fields[0]\n",
    "        gt = fields[1]\n",
    "        content = ' '.join(fields[2:])\n",
    "        id_gts[tweet_id] = content\n",
    "        sentiments.append(Sentiment[gt])\n",
    "\n",
    "    return id_gts, tuple(sentiments)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Define GloVe data preparation functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_glove_data() -> ShouldMarkedAsBackground:\n",
    "    if path_exists(glove_data_dir) and len(ls(glove_data_dir)) == 4:\n",
    "        return\n",
    "\n",
    "    glove_data_pack_name = 'glove.6B.zip'\n",
    "\n",
    "    hf_hub_download(\n",
    "        repo_id='stanfordnlp/glove',\n",
    "        filename=glove_data_pack_name,\n",
    "        local_dir=dataset_base_path,\n",
    "        revision='1db2080b2d94def6e5b0386a523102f9d8849e9d',\n",
    "    )\n",
    "\n",
    "    # perform shell command using python code since the thread management can be done in python.\n",
    "    mkdir(glove_data_dir)\n",
    "    unzip_file_to(\n",
    "        f'{dataset_base_path}/{glove_data_pack_name}',\n",
    "        destination=glove_data_dir\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "@lru_cache(typed=True)\n",
    "def parse_glove_data(file_name_: str) -> tuple[dict[str, int], np.ndarray]:\n",
    "    \"\"\"\n",
    "    Parse the GloVe data from a given file.\n",
    "\n",
    "    Args:\n",
    "        file_name_ (str): The name of the file containing the GloVe data.\n",
    "\n",
    "    Returns:\n",
    "        tuple[dict[str, int], np.ndarray]: A tuple containing two elements:\n",
    "            - A dictionary mapping words to their corresponding indices.\n",
    "            - A numpy array containing the word vectors.\n",
    "    \"\"\"\n",
    "    file_frame = pd.read_csv(\n",
    "        f\"{glove_data_dir}/{file_name_}\",\n",
    "        delimiter=' ',\n",
    "        quoting=csv.QUOTE_NONE,\n",
    "        header=None,\n",
    "        encoding='utf-8',\n",
    "        skip_blank_lines=True,\n",
    "    )\n",
    "    \n",
    "    vectors = file_frame.iloc[:, 1:].to_numpy(dtype=np.float64)\n",
    "    \n",
    "    # Add a custom <pad> to the top of the vectors\n",
    "    vectors = np.insert(vectors, 0, np.zeros(vectors.shape[1]), axis=0)\n",
    "\n",
    "    return (\n",
    "        file_frame.reset_index().set_index(0)['index'].to_dict(),\n",
    "        vectors\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Define data preprocessing functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def filter_text(src: str, /, *, patterns: Sequence[re.Pattern]) -> str:\n",
    "    \"\"\"\n",
    "    Filters the given source text by removing all occurrences of the specified patterns.\n",
    "\n",
    "    Args:\n",
    "        src (str): The source text to be filtered.\n",
    "        patterns (Sequence[Pattern]): A sequence of regular expression patterns to be removed from the source text.\n",
    "\n",
    "    Returns:\n",
    "        str: The filtered text with all occurrences of the specified patterns removed.\n",
    "    \"\"\"\n",
    "    filtered = copy(src)\n",
    "\n",
    "    for pattern in patterns:\n",
    "        filtered = pattern.sub('', filtered)\n",
    "\n",
    "    return filtered\n",
    "\n",
    "\n",
    "def process_texts(src_dict: dict[Any, str], callable: Callable, *args, **kwargs) -> dict[Any, str]:\n",
    "    \"\"\"\n",
    "    Process a dictionary of texts using a callable function in parallel using a thread pool executor.\n",
    "\n",
    "    Args:\n",
    "        src_dict (dict[Any, str]): A dictionary containing the texts to be processed.\n",
    "        callable (Callable[[str], Any]): A callable function that will be applied to each text.\n",
    "        *args: Variable length argument list to be passed to the callable function.\n",
    "        **kargs: Arbitrary keyword arguments to be passed to the callable function.\n",
    "\n",
    "    Returns:\n",
    "        dict[Any, str]: A dictionary containing the processed texts.\n",
    "    \"\"\"\n",
    "\n",
    "    multi_process = False\n",
    "\n",
    "    if multi_process:\n",
    "        with ProcessPoolExecutor(max_workers=(cpu_count() or 1)) as executor:\n",
    "            future_to_key = {\n",
    "                executor.submit(callable, src_dict[key], *args, **kwargs): key for key in src_dict\n",
    "            }\n",
    "            return {\n",
    "                future_to_key[future]: future.result()\n",
    "                for future in as_completed(future_to_key)\n",
    "            }\n",
    "\n",
    "    return {\n",
    "        key: callable(value, *args, **kwargs)\n",
    "        for key, value in src_dict.items()\n",
    "    }\n",
    "\n",
    "\n",
    "def run_pipelines(\n",
    "    callables: Sequence[Callable[[str], str]],\n",
    "    /,\n",
    "    *,\n",
    "    tweets: dict[TweetID, str]\n",
    ") -> dict[str, str]:\n",
    "    \"\"\"\n",
    "    Run a sequence of callables on a dictionary of texts in parallel using a thread pool executor.\n",
    "\n",
    "    Args:\n",
    "        callables (Sequence[Callable[[dict[str, str]], dict[str, str]]]): A sequence of callable functions to be applied to the dictionary of texts.\n",
    "        tweets (dict[str, str]): A dictionary containing the texts to be processed.\n",
    "\n",
    "    Returns:\n",
    "        dict[str, str]: A dictionary containing the processed texts.\n",
    "    \"\"\"\n",
    "    processed = copy(tweets)\n",
    "\n",
    "    for callable in callables:\n",
    "        processed = process_texts(processed, callable)\n",
    "\n",
    "    return processed"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Define confusion matrix function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def show_confusion(*, predict_results: dict[TweetID, Sentiment], test_set_file_name_: str) -> None:\n",
    "    \"\"\"\n",
    "    Display the confusion matrix based on the predicted results and the sentiment labels from the test set file.\n",
    "\n",
    "    Args:\n",
    "        predict_results (dict[TweetID, Sentiment]): A dictionary containing the predicted sentiment for each tweet ID.\n",
    "        test_set_file_name_ (str): The file name of the test set containing the sentiment labels for each tweet ID.\n",
    "    \"\"\"\n",
    "    id_tweets, sentiments = get_tweets_from(test_set_file_name_)\n",
    "\n",
    "    conf: Final[dict[Sentiment, dict[Sentiment, int]]] = defaultdict(\n",
    "        lambda: {\n",
    "            Sentiment.positive: 0,\n",
    "            Sentiment.negative: 0,\n",
    "            Sentiment.neutral: 0,\n",
    "        }\n",
    "    )\n",
    "\n",
    "    for tweet_id, sentiment in zip(id_tweets, sentiments):\n",
    "        if tweet_id in predict_results:\n",
    "            pred = predict_results[tweet_id]\n",
    "        else:\n",
    "            pred = Sentiment.neutral\n",
    "        conf[pred][sentiment] += 1\n",
    "\n",
    "    print(''.ljust(12) + '  '.join(Sentiment.gts()))\n",
    "\n",
    "    for c1 in Sentiment:\n",
    "        print(c1.name.ljust(12), end='')\n",
    "        for c2 in Sentiment:\n",
    "            if c1_sum := sum(conf[c1].values()) > 0:\n",
    "                p = conf[c1][c2] / float(c1_sum)\n",
    "                print(f\"{p:.3f}     \", end='')\n",
    "            else:\n",
    "                print('0.000     ', end='')\n",
    "        print()\n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Define evaluation functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate(predict_results: dict[TweetID, Sentiment], test_set_file_name_: str, classifier_name_: str) -> None:\n",
    "    \"\"\"\n",
    "    Evaluate the performance of a sentiment classifier by comparing the predicted results with the ground truth sentiment labels.\n",
    "\n",
    "    Parameters:\n",
    "        - predict_results: A dictionary mapping TweetIDs to predicted Sentiments.\n",
    "        - test_set_file_name_: The name of the test set file.\n",
    "        - classifier_name_: The name of the classifier.\n",
    "    \"\"\"\n",
    "    id_tweets, sentiments = get_tweets_from(test_set_file_name_)\n",
    "\n",
    "    acc_by_class: Final[dict[Sentiment, dict[str, int]]] = defaultdict(\n",
    "        lambda: {'tp': 0, 'fp': 0, 'tn': 0, 'fn': 0}\n",
    "    )\n",
    "\n",
    "    for tweet_id, sentiment in zip(id_tweets, sentiments):\n",
    "        if tweet_id in predict_results:\n",
    "            pred = predict_results[tweet_id]\n",
    "        else:\n",
    "            pred = Sentiment.neutral\n",
    "\n",
    "        if sentiment == pred:\n",
    "            acc_by_class[sentiment]['tp'] += 1\n",
    "        else:\n",
    "            acc_by_class[sentiment]['fn'] += 1\n",
    "            acc_by_class[pred]['fp'] += 1\n",
    "\n",
    "    cat_count = 0\n",
    "    item_count = 0\n",
    "    macro: dict[str, float] = {'p': 0.0, 'r': 0.0, 'f1': 0.0}\n",
    "    micro: dict[str, float] = {'p': 0.0, 'r': 0.0, 'f1': 0.0}\n",
    "    sem_eval_macro: dict[str, float] = {'p': 0.0, 'r': 0.0, 'f1': 0.0}\n",
    "\n",
    "    micro_tp = 0.0\n",
    "    micro_fp = 0.0\n",
    "    micro_tn = 0.0\n",
    "    micro_fn = 0.0\n",
    "\n",
    "    cat_f1s: dict[Sentiment, float] = {}\n",
    "\n",
    "    for cat, acc in acc_by_class.items():\n",
    "        cat_count += 1\n",
    "\n",
    "        micro_tp += acc['tp']\n",
    "        micro_fp += acc['fp']\n",
    "        micro_tn += acc['tn']\n",
    "        micro_fn += acc['fn']\n",
    "\n",
    "        p = 0.0\n",
    "        if (acc['tp'] + acc['fp']) > 0:\n",
    "            p = float(acc['tp']) / (acc['tp'] + acc['fp'])\n",
    "\n",
    "        r = 0.0\n",
    "        if (acc['tp'] + acc['fn']) > 0:\n",
    "            r = float(acc['tp']) / (acc['tp'] + acc['fn'])\n",
    "\n",
    "        f1 = 0.0\n",
    "        if (p + r) > 0:\n",
    "            f1 = 2 * p * r / (p + r)\n",
    "\n",
    "        cat_f1s[cat] = f1\n",
    "\n",
    "        n = acc['tp'] + acc['fn']\n",
    "\n",
    "        macro['p'] += p\n",
    "        macro['r'] += r\n",
    "        macro['f1'] += f1\n",
    "\n",
    "        if cat in ['positive', 'negative']:\n",
    "            sem_eval_macro['p'] += p\n",
    "            sem_eval_macro['r'] += r\n",
    "            sem_eval_macro['f1'] += f1\n",
    "\n",
    "        item_count += n\n",
    "\n",
    "    micro['p'] = micro_tp / (micro_tp + micro_fp)\n",
    "    micro['r'] = micro_tp / (micro_tp + micro_fn)\n",
    "    micro['f1'] = 2 * micro['p'] * micro['r'] / (micro['p'] + micro['r'])\n",
    "\n",
    "    sem_eval_macro_f1 = sem_eval_macro['f1'] / 2\n",
    "\n",
    "    print(\n",
    "        f\"{test_set_file_name_} ({classifier_name_}): {sem_eval_macro_f1:.3f}\"\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Load training set, dev set and testing set\n",
    "Here, you need to load the training set, the development set and the test set. For better classification results, you may need to preprocess tweets before sending them to the classifiers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_data, training_sentiments = get_tweets_from(training_data_file_name)\n",
    "dev_data, dev_sentiments = get_tweets_from(devlopment_data_file_name)\n",
    "test_datas, test_sentiments = zip(*[\n",
    "    get_tweets_from(file_name)\n",
    "    for file_name in test_set_names\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Download network resources"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "glove_prepare_task = BackgroundTask(prepare_glove_data)\n",
    "\n",
    "\n",
    "def download_nltk_resources(resource_names: Sequence[str]) -> ShouldMarkedAsBackground:\n",
    "    for resource_name in resource_names:\n",
    "        nltk_download(resource_name, quiet=True)\n",
    "\n",
    "\n",
    "nltk_prepare_task = BackgroundTask(\n",
    "    download_nltk_resources,\n",
    "    ('stopwords', 'vader_lexicon', 'punkt', 'wordnet',)\n",
    ")\n",
    "\n",
    "\n",
    "def pre_load_bert_tokenizer() -> ShouldMarkedAsBackground:\n",
    "    BertTokenizer.from_pretrained(target_bert_model_name)\n",
    "    BertModel.from_pretrained(target_bert_model_name)\n",
    "\n",
    "\n",
    "bert_prepare_task = BackgroundTask(pre_load_bert_tokenizer)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Lowercase the tweets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Lowercase all the words.\n",
    "\n",
    "def lowercase_tweet(tweet: str, /) -> str:\n",
    "    return tweet.lower()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Regexp filter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filter the tweets based on the selected regexp patterns.\n",
    "\n",
    "re_flags = re.IGNORECASE | re.MULTILINE\n",
    "\n",
    "pattern_html_tags = re.compile(r'<[^>]+?>', re_flags)\n",
    "pattern_mentions = re.compile(r'@[a-zA-Z0-9_]+', re_flags)\n",
    "pattern_hashtags = re.compile(r'#[a-zA-Z0-9_]+', re_flags)\n",
    "pattern_alphanumeric = re.compile(r'[^a-zA-Z0-9 ]+?', re_flags)\n",
    "pattern_only_one_char = re.compile(r'\\b[a-zA-Z0-9]\\b', re_flags)\n",
    "pattern_fully_numeric = re.compile(r'\\b([0-9]+)\\b', re_flags)\n",
    "\n",
    "pattern_punctuation = re.compile(\n",
    "    \"[\" + re.escape(punctuation+\"“”…‘’\") + \"]+?\",\n",
    "    re_flags\n",
    ")\n",
    "custom_removal_puncuations = punctuation+'“”…‘’'\n",
    "punctuation_translator = str.maketrans(\n",
    "    custom_removal_puncuations,\n",
    "    ' ' * len(custom_removal_puncuations)\n",
    ")\n",
    "\n",
    "pattern_url = re.compile(\n",
    "    r'(?:[a-zA-Z][a-zA-Z0-9+-.]*:)?'\n",
    "    r'(//(?:[a-zA-Z0-9-._~%!$&\\'()*+,;=:]*(?::[a-zA-Z0-9-._~%!$&\\'()*+,;=:]+)?@)?'\n",
    "    r'(?:\\[[0-9a-fA-F:.]+]|(?:[a-zA-Z0-9-]+\\.)*[a-zA-Z]{2,}|[0-9.]+|localhost)'\n",
    "    r'(?::\\d+)?)(/[a-zA-Z0-9-._~%!$&\\'()*+,;=:@]*/?)*'\n",
    "    r'(?:\\?[a-zA-Z0-9-._~%!$&\\'()*+,;=:@/]*)?'\n",
    "    r'(?:#[a-zA-Z0-9-._~%!$&\\'()*+,;=:@/]*)?',\n",
    "    re_flags\n",
    ")\n",
    "\n",
    "# all_emojis = tuple(EMOJI_DATA.keys())\n",
    "# pattern_emojis = re.compile('|'.join(map(re.escape, all_emojis)) + '?')\n",
    "\n",
    "pattern_ampm = re.compile(r'([0-9]+(am|pm))')\n",
    "pattern_ordinals = re.compile(r'([0-9]+)(?:st|nd|rd|th)')\n",
    "\n",
    "selected_filter_patterns: tuple[re.Pattern[str], ...] = (\n",
    "    pattern_url,\n",
    "    pattern_html_tags,\n",
    "    pattern_mentions,\n",
    "    pattern_hashtags,\n",
    "    pattern_fully_numeric,\n",
    "    pattern_only_one_char,\n",
    "    pattern_ampm,\n",
    "    pattern_ordinals,\n",
    ")\n",
    "\n",
    "\n",
    "def regexp_filter(tweet: str, /) -> str:\n",
    "    return filter_text(tweet, patterns=selected_filter_patterns)\n",
    "\n",
    "\n",
    "def punctuation_filter(tweet: str, /) -> str:\n",
    "    return tweet.translate(punctuation_translator)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Remove emojis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_emojis(tweet: str, /) -> str:\n",
    "    return demojize(tweet, delimiters=('', ''))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Remove numbers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "remove_digits = str.maketrans('', '', digits)\n",
    "\n",
    "\n",
    "def remove_numbers(tweet: str, /) -> str:\n",
    "    return tweet.translate(remove_digits)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Remove non-English words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langdetect import detect\n",
    "\n",
    "def remove_non_en(tweet: str, /) -> str:\n",
    "    try:\n",
    "        if detect(tweet) == 'en':\n",
    "            return tweet\n",
    "        else:\n",
    "            return ''\n",
    "    except:\n",
    "        return ''"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Tokenization & Lemmatization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "nltk_prepare_task.wait()\n",
    "\n",
    "lemmatizer = WordNetLemmatizer()\n",
    "tokenizer = TweetTokenizer(\n",
    "    reduce_len=True,\n",
    "    strip_handles=True,\n",
    "    preserve_case=False\n",
    ")\n",
    "\n",
    "custom_preserved_words: frozenset[str] = frozenset((\n",
    "    'not', \"wouldn't\", 'nor',\n",
    "    'but', \"weren't\", 'couldn',\n",
    "    'didn', 'doesn', 'hadn',\n",
    "    'hasn', 'haven', 'isn', 'mightn',\n",
    "    \"aren't\", 'mustn', 'needn',\n",
    "    \"shan't\", 'shouldn', 'wasn',\n",
    "    \"mustn't\", \"didn't\", \"doesn't\",\n",
    "    \"mightn't\", \"isn't\", \"shouldn't\",\n",
    "    \"mustn't\", \"haven\", \"isn\",\n",
    "    \"didn't\", \"aren't\", \"wouldn't\",\n",
    "    \"shouldn't\", \"couldn't\", \"hadn't\",\n",
    "    \"don't\", \"won't\", \"can't\",\n",
    "    \"hasn't\", \"wasn't\", 'the'\n",
    "))\n",
    "custom_stop_words: frozenset[str] = frozenset((\n",
    "    \"call\", 'upon', 'still', 'nevertheless', \n",
    "    'down', 'every', 'forty', '‘re', 'always', \n",
    "    'whole', 'side', 'now', 'however', \n",
    "    'an', 'show', 'least', 'give', 'below', \n",
    "    'did', 'sometimes', 'which', \"'s\", \n",
    "    'nowhere', 'per', 'hereupon', 'yours', \n",
    "    'she', 'moreover', 'eight', 'somewhere', \n",
    "    'within', 'whereby', 'few', 'has', 'so', \n",
    "    'have', 'for', 'noone', 'top', 'were', \n",
    "    'those', 'thence', 'eleven', 'after', \n",
    "    '’ll', 'others', 'ourselves', \n",
    "    'themselves', 'though', 'that', 'just', '’s', \n",
    "    'before', 'had', 'toward', 'another', 'should', \n",
    "    'herself', 'and', 'these', 'such', 'elsewhere',\n",
    "    'further', 'next', 'indeed', 'bottom', 'anyone',\n",
    "    'his', 'each', 'then', 'both', 'became', 'third',\n",
    "    'whom', '‘ve', 'mine', 'take', 'many', 'anywhere',\n",
    "    'to', 'well', 'thereafter', 'besides', 'almost',\n",
    "    'front', 'fifteen', 'towards', 'be', 'herein',\n",
    "    'two', 'using', 'whatever', 'please', 'perhaps',\n",
    "    'full', 'ca', 'we', 'latterly', 'here', 'therefore',\n",
    "    'us', 'how', 'was', 'made', 'or', 'may', '’re',\n",
    "    'namely', \"'ve\", 'anyway', 'amongst', 'used', 'ever',\n",
    "    'of', 'there', 'than', 'why', 'really', 'whither', 'in',\n",
    "    'only', 'wherein', 'last', 'under', 'own', 'therein',\n",
    "    'go', 'seems', '‘m', 'wherever', 'either', 'someone',\n",
    "    'up', 'doing', 'on', 'rather', 'ours', 'again', 'same',\n",
    "    'over', '‘s', 'latter', 'during', 'done', \"'re\", \n",
    "    'put', \"'m\", 'much', 'among', 'seemed', 'into', \n",
    "    'once', 'my', 'otherwise', 'part', 'everywhere',\n",
    "    'myself', 'must', 'will', 'am', 'although',\n",
    "    'as', 'beyond', 'are', 'too', 'becomes', 'does', \n",
    "    'a', 'everyone', 'some', 'regarding', '‘ll', \n",
    "    'throughout', 'yourselves', 'him', \"'d\", 'it',\n",
    "    'himself', 'whether', 'move', '’m', 'hereafter',\n",
    "    're', 'while', 'whoever', 'your', 'first', 'amount',\n",
    "    'twelve', 'serious', 'other', 'any', 'off', 'seeming',\n",
    "    'four', 'itself', 'nothing', 'beforehand', 'make', 'out',\n",
    "    'very', 'already', 'various', 'until', 'hers', 'they', \n",
    "    'them', 'where', 'would', 'since', 'everything', 'at', \n",
    "    'together', 'yet', 'more', 'six', 'back', 'with', 'thereupon',\n",
    "    'becoming', 'around', 'due', 'keep', 'somehow', 'across',\n",
    "    'all', 'when', 'i', 'empty', 'nine', 'five', 'get', 'see',\n",
    "    'been', 'name', 'between', 'hence', 'ten', 'several', 'from',\n",
    "    'whereupon', 'through', 'hereby', \"'ll\", 'alone', 'something',\n",
    "    'formerly','above', 'onto', 'except', 'enough', 'become', \n",
    "    'behind', '’d', 'its', 'most', 'n’t', 'might', 'whereas',\n",
    "    'anything', 'if', 'her', 'via', 'fifty', 'is', 'thereby', \n",
    "    'twenty', 'often', 'whereafter', 'their', 'also', 'anyhow', \n",
    "    'our', 'could', 'because', 'who', 'beside', 'by', 'whence', \n",
    "    'being', 'meanwhile', 'this', 'afterwards', 'whenever', 'mostly',\n",
    "    'what', 'one', 'nobody', 'seem', 'do', '‘d', 'say',\n",
    "    'thus', 'unless', 'along', 'yourself', 'former', 'thru',\n",
    "    'he', 'hundred', 'three', 'sixty', 'me', 'sometime', 'amp',\n",
    "    'whose', 'you', 'quite', '’ve', 'about', 'even',\n",
    "    'monday', 'tuesday', 'wednesday', 'thursday', 'friday',\n",
    "    'saturday', 'sunday', 'january', 'february', 'march', 'april',\n",
    "    'may', 'june', 'july', 'august', 'september', 'october',\n",
    "    'november', 'december'\n",
    "))\n",
    "stop_words = (frozenset(stopwords.words('english')) | custom_stop_words) - custom_preserved_words\n",
    "\n",
    "\n",
    "def nltk_tokenize_anti_stopwords_lemmatize(tweet: str, /) -> str:\n",
    "    wordnet.ensure_loaded()\n",
    "    tokens = tokenizer.tokenize(tweet)\n",
    "    return ' '.join(\n",
    "        lemmatizer.lemmatize(token)\n",
    "        for token in tokens\n",
    "        if token not in stop_words\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Fix contractions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fix_contractions(tweet: str, /) -> str:\n",
    "    return f'{contractions.fix(tweet)}'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Run all preprocessing steps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_pipelines = (\n",
    "    lowercase_tweet,\n",
    "    fix_contractions,\n",
    "    regexp_filter,\n",
    "    remove_emojis,\n",
    "    remove_numbers,\n",
    "    punctuation_filter,\n",
    "    nltk_tokenize_anti_stopwords_lemmatize,\n",
    ")\n",
    "\n",
    "cleaned_training_tweets = run_pipelines(\n",
    "    all_pipelines,\n",
    "    tweets=training_data\n",
    ")\n",
    "\n",
    "cleaned_dev_tweets = run_pipelines(\n",
    "    all_pipelines,\n",
    "    tweets=dev_data\n",
    ")\n",
    "\n",
    "cleaned_test_tweets = [\n",
    "    run_pipelines(\n",
    "        all_pipelines,\n",
    "        tweets=test_data\n",
    "    )\n",
    "    for test_data in test_datas\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Show the top 10 most frequent words in the training set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "        word   freq\n",
      "0        the  34055\n",
      "1        not   6834\n",
      "2   tomorrow   5911\n",
      "3        but   3702\n",
      "4        day   3650\n",
      "5      going   3282\n",
      "6      night   2558\n",
      "7       like   2405\n",
      "8       time   2367\n",
      "9       want   1848\n",
      "10       new   1699\n",
      "11      game   1666\n",
      "12      know   1481\n",
      "13     today   1443\n",
      "14      good   1364\n",
      "15     think   1252\n",
      "16   tonight   1240\n",
      "17      come   1230\n",
      "18    cannot   1157\n",
      "19      love   1132\n"
     ]
    }
   ],
   "source": [
    "all_words = ' '.join(cleaned_training_tweets.values()).split()\n",
    "word_freq = Counter(all_words)\n",
    "\n",
    "freq_frame = pd.DataFrame(\n",
    "    word_freq.most_common(20),\n",
    "    columns=['word', 'freq']\n",
    ")\n",
    "\n",
    "print(freq_frame)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['josh hamilton got the mandatory boo returned angel stadium daily news',\n",
      " 'highlight grayson allen lead duke past william mary',\n",
      " 'happy birthday know singapore but happy birthday',\n",
      " 'kicking the world cup black v tonga yeeeaah looking forward laxing popcorn '\n",
      " 'glass bubbly',\n",
      " 'never ending gold rush china china the largest producer gold the biggest '\n",
      " 'china daily',\n",
      " 'funny thing think david price going bombed tomorrow win the',\n",
      " 'playing foo fighter cold day the sun',\n",
      " 'samsung tease round smartwatch heavy apple watch influence samsung unpacked '\n",
      " 'event brough',\n",
      " 'pierce the veil northern light sold albany ny oct',\n",
      " 'backing hdd preparation the tb sshd coming new p',\n",
      " 'wheel dad gf tonight but worth kenny chesney jason aldean',\n",
      " 'think work buying complete manga like fullmetal alchemist naruto not sure',\n",
      " 'ready madonna the',\n",
      " 'cannot believe mariah carey want christmas playing right',\n",
      " 'pancake delicious perfect sleep tomorrow going ascot day long']\n",
      "128\n"
     ]
    }
   ],
   "source": [
    "# TODO: Dev code.\n",
    "from pprint import pprint\n",
    "import random\n",
    "# generate a random number between 0 and 100\n",
    "\n",
    "window_size = 15\n",
    "rand_num = random.randint(0, len(cleaned_training_tweets) - window_size)\n",
    "\n",
    "pprint(list(cleaned_training_tweets.values())[rand_num:rand_num+window_size])\n",
    "print(rand_num)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### TF-IDF Vectorization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(45101, 4940)\n"
     ]
    }
   ],
   "source": [
    "from scipy.sparse import csr_matrix\n",
    "\n",
    "vectorizer = TfidfVectorizer(\n",
    "    analyzer='word',\n",
    "    stop_words='english',\n",
    "    encoding='utf-8',\n",
    "    lowercase=False,\n",
    "    min_df=3,\n",
    "    max_df=0.8,\n",
    "    max_features=4940,\n",
    "    ngram_range=(1, 7)\n",
    ")\n",
    "\n",
    "training_matrix = np.asarray(\n",
    "    csr_matrix(\n",
    "        vectorizer.fit_transform(cleaned_training_tweets.values())\n",
    "    ).todense()\n",
    ")\n",
    "dev_matrix = np.asarray(\n",
    "    csr_matrix(vectorizer.transform(cleaned_dev_tweets.values())).todense()\n",
    ")\n",
    "test_matrix = [\n",
    "    np.asarray(csr_matrix(vectorizer.transform(test_data.values())).todense())\n",
    "    for test_data in cleaned_test_tweets\n",
    "]\n",
    "\n",
    "print(training_matrix.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Build sentiment classifiers\n",
    "You need to create your own classifiers (at least 3 classifiers). For each classifier, you can choose between the bag-of-word features and the word-embedding-based features. Each classifier has to be evaluated over 3 test sets. Make sure your classifier produce consistent performance across the test sets. Marking will be based on the performance over all 5 test sets (2 of them are not provided to you)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "    positive    0.59484   0.78191   0.67567      1504\n",
      "    negative    0.62171   0.33932   0.43902       557\n",
      "     neutral    0.72640   0.61769   0.66765      1470\n",
      "\n",
      "    accuracy                        0.64373      3531\n",
      "   macro avg    0.64765   0.57964   0.59411      3531\n",
      "weighted avg    0.65385   0.64373   0.63500      3531\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    positive    0.54842   0.72795   0.62556       669\n",
      "    negative    0.60909   0.33168   0.42949       202\n",
      "     neutral    0.75556   0.65784   0.70332       982\n",
      "\n",
      "    accuracy                        0.64760      1853\n",
      "   macro avg    0.63769   0.57249   0.58612      1853\n",
      "weighted avg    0.66481   0.64760   0.64540      1853\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    positive    0.55296   0.77009   0.64371       983\n",
      "    negative    0.56502   0.34711   0.43003       363\n",
      "     neutral    0.71919   0.54792   0.62198      1033\n",
      "\n",
      "    accuracy                        0.60908      2379\n",
      "   macro avg    0.61239   0.55504   0.56524      2379\n",
      "weighted avg    0.62698   0.60908   0.60167      2379\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# SVM\n",
    "\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "model = LinearSVC(verbose=False, max_iter=1000, dual=False)\n",
    "model.fit(\n",
    "    training_matrix,\n",
    "    [sentiments.value for sentiments in training_sentiments]\n",
    ")\n",
    "\n",
    "for x in range(3):\n",
    "    svm_predictions = model.predict(test_matrix[x])\n",
    "    svm_report = classification_report(\n",
    "        [sentiments.value for sentiments in test_sentiments[x]],\n",
    "        svm_predictions,\n",
    "        target_names=Sentiment.gts(),\n",
    "        digits=5\n",
    "    )\n",
    "\n",
    "    print(svm_report)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Navie Bayes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "    positive    0.57676   0.71941   0.64024      1504\n",
      "    negative    0.54662   0.30521   0.39171       557\n",
      "     neutral    0.67485   0.61701   0.64463      1470\n",
      "\n",
      "    accuracy                        0.61144      3531\n",
      "   macro avg    0.59941   0.54721   0.55886      3531\n",
      "weighted avg    0.61284   0.61144   0.60286      3531\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    positive    0.53286   0.67862   0.59698       669\n",
      "    negative    0.57647   0.24257   0.34146       202\n",
      "     neutral    0.72817   0.67923   0.70285       982\n",
      "\n",
      "    accuracy                        0.63141      1853\n",
      "   macro avg    0.61250   0.53348   0.54709      1853\n",
      "weighted avg    0.64112   0.63141   0.62523      1853\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    positive    0.54476   0.73042   0.62408       983\n",
      "    negative    0.48485   0.30854   0.37710       363\n",
      "     neutral    0.68675   0.55179   0.61192      1033\n",
      "\n",
      "    accuracy                        0.58848      2379\n",
      "   macro avg    0.57212   0.53025   0.53770      2379\n",
      "weighted avg    0.59727   0.58848   0.58111      2379\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.naive_bayes import BernoulliNB\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "model = BernoulliNB(\n",
    "    alpha=0.1,\n",
    "    fit_prior=True,\n",
    ")\n",
    "model.fit(\n",
    "    training_matrix,\n",
    "    [sentiments.value for sentiments in training_sentiments]\n",
    ")\n",
    "\n",
    "for x in range(3):\n",
    "    svm_predictions = model.predict(test_matrix[x])\n",
    "    svm_report = classification_report(\n",
    "        [sentiments.value for sentiments in test_sentiments[x]],\n",
    "        svm_predictions,\n",
    "        target_names=Sentiment.gts(),\n",
    "        digits=5\n",
    "    )\n",
    "\n",
    "    print(svm_report)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### LSTM Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using cuda device\n"
     ]
    }
   ],
   "source": [
    "device = (\n",
    "    \"cuda\"\n",
    "    if torch.cuda.is_available()\n",
    "    else \"mps\"\n",
    "    if torch.backends.mps.is_available()\n",
    "    else \"cpu\"\n",
    ")\n",
    "print(f\"Using {device} device\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### GloVe Embedding Vectorization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "@final\n",
    "class GloVeVectorizer:\n",
    "    def __init__(self, word_indexes: dict[str, int], word_vectors: np.ndarray):\n",
    "        self.word_indexes = word_indexes\n",
    "        self.word_vectors = word_vectors\n",
    "\n",
    "    def __vectorize_impl(self, tokens: Sequence[str], /) -> np.ndarray:\n",
    "        vecs = np.zeros(\n",
    "            (len(tokens), self.word_vectors.shape[1]),\n",
    "            dtype=np.float64\n",
    "        )\n",
    "        for i, token in enumerate(tokens):\n",
    "            if token in self.word_indexes:\n",
    "                vecs[i] = self.word_vectors[self.word_indexes[token]]\n",
    "        return vecs\n",
    "\n",
    "    def __ordinalization_impl(self, tokens: Sequence[str], /) -> np.ndarray:\n",
    "        return np.asarray([\n",
    "            self.word_indexes.get(token, 400001) # 400001 is the index of the <UNK> token.\n",
    "            for token in tokens\n",
    "        ])\n",
    "\n",
    "    @staticmethod\n",
    "    def __largest_element_count(element_sets: Sequence[Sequence | np.ndarray], /) -> int:\n",
    "        return max(\n",
    "            len(element)\n",
    "            for element in element_sets\n",
    "        )\n",
    "\n",
    "    @staticmethod\n",
    "    def __expand_2d_to_size(\n",
    "        _2d_targets: Sequence[np.ndarray],\n",
    "        /,\n",
    "        *,\n",
    "        size: int\n",
    "    ) -> list[np.ndarray]:\n",
    "        assert size > 0\n",
    "        assert len(_2d_targets) > 0\n",
    "        return [\n",
    "            np.vstack((\n",
    "                _2d_target,\n",
    "                np.zeros(\n",
    "                    (size - _2d_target.shape[0], _2d_target.shape[1]),\n",
    "                    dtype=np.float64\n",
    "                )\n",
    "            ))\n",
    "            for _2d_target in _2d_targets\n",
    "        ]\n",
    "\n",
    "    @staticmethod\n",
    "    def __expand_1d_to_size(\n",
    "        _1d_targets: Sequence[np.ndarray],\n",
    "        /,\n",
    "        *,\n",
    "        size: int\n",
    "    ) -> list[np.ndarray]:\n",
    "        assert size > 0\n",
    "        assert len(_1d_targets) > 0\n",
    "        return [\n",
    "            np.pad(\n",
    "                _1d_target,\n",
    "                (0, size - _1d_target.shape[0]),\n",
    "                mode='constant',\n",
    "                constant_values=0 # 0 is the index of the <PAD> token. (self added)\n",
    "            )\n",
    "            for _1d_target in _1d_targets\n",
    "        ]\n",
    "\n",
    "    def vectorize(self, tweets: dict[TweetID, str], /) -> np.ndarray:\n",
    "        tokens = [\n",
    "            self.__vectorize_impl(tweet.split())\n",
    "            for tweet in tweets.values()\n",
    "        ]\n",
    "        return np.asarray(\n",
    "            self.__expand_2d_to_size(\n",
    "                tokens,\n",
    "                size=self.__largest_element_count(tokens)\n",
    "            )\n",
    "        )\n",
    "\n",
    "    def ordinalization(self, tweets: dict[TweetID, str], /) -> np.ndarray:\n",
    "        indexes = [\n",
    "            self.__ordinalization_impl(tweet.split())\n",
    "            for tweet in tweets.values()\n",
    "        ]\n",
    "        return np.asarray(\n",
    "            self.__expand_1d_to_size(\n",
    "                indexes,\n",
    "                size=self.__largest_element_count(indexes)\n",
    "            ),\n",
    "            dtype=np.int32\n",
    "        )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Define LSTM model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "class AttentionMechanism(torch.nn.Module):\n",
    "    \"\"\"\n",
    "    A module that implements an attention mechanism.\n",
    "\n",
    "    Args:\n",
    "        hidden_size (int): The size of the hidden state.\n",
    "\n",
    "    Attributes:\n",
    "        hidden_size (int): The size of the hidden state.\n",
    "        attention_weights (torch.Tensor): The attention weights.\n",
    "\n",
    "    Methods:\n",
    "        forward(lstm_output: torch.Tensor) -> torch.Tensor: Performs the forward pass of the attention mechanism.\n",
    "\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, hidden_size: int) -> None:\n",
    "        super(AttentionMechanism, self).__init__()\n",
    "        self.hidden_size = hidden_size\n",
    "        self.attention_weights = torch.nn.Parameter(\n",
    "            torch.Tensor(hidden_size, 1)\n",
    "        )\n",
    "        torch.nn.init.xavier_uniform_(self.attention_weights.data, gain=1.414)\n",
    "\n",
    "    def forward(self, lstm_output: torch.Tensor) -> torch.Tensor:\n",
    "        attention_scores = torch.matmul(lstm_output, self.attention_weights)\n",
    "        attention_scores = attention_scores.squeeze(2)\n",
    "        attention_weights = torch.softmax(attention_scores, dim=1)\n",
    "        weighted_output = lstm_output * attention_weights.unsqueeze(2)\n",
    "        return weighted_output.sum(1)\n",
    "\n",
    "\n",
    "class SentimentLSTMModel(torch.nn.Module):\n",
    "    \"\"\"\n",
    "    A sentiment analysis LSTM model.\n",
    "\n",
    "    This model takes in a sequence of input tokens and predicts the sentiment of the input text.\n",
    "    It consists of an embedding layer, a bidirectional LSTM layer, an attention mechanism, and a fully connected layer.\n",
    "\n",
    "    Args:\n",
    "        vocab_size (int): The size of the vocabulary.\n",
    "        embedding_dim (int): The dimension of the word embeddings.\n",
    "        hidden_size (int): The size of the hidden state of the LSTM.\n",
    "        output_size (int): The number of output classes.\n",
    "        pretrained_embeddings (torch.Tensor): Pretrained word embeddings.\n",
    "\n",
    "    Attributes:\n",
    "        hidden_size (int): The size of the hidden state of the LSTM.\n",
    "        embedding (torch.nn.Embedding): The embedding layer.\n",
    "        lstm (torch.nn.LSTM): The bidirectional LSTM layer.\n",
    "        attention (AttentionMechanism): The attention mechanism.\n",
    "        fc (torch.nn.Linear): The fully connected layer.\n",
    "        dropout (torch.nn.Dropout): The dropout layer.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(\n",
    "        self,\n",
    "        embedding_dim: int,\n",
    "        hidden_size: int,\n",
    "        output_size: int,\n",
    "        pretrained_embeddings: torch.Tensor\n",
    "    ):\n",
    "        super(SentimentLSTMModel, self).__init__()\n",
    "\n",
    "        self.hidden_size = hidden_size\n",
    "\n",
    "        self.embedding = torch.nn.Embedding.from_pretrained(\n",
    "            embeddings=pretrained_embeddings,\n",
    "            padding_idx=0,\n",
    "            freeze=False\n",
    "        )\n",
    "        self.embedding.weight.requires_grad = False\n",
    "\n",
    "        self.lstm = torch.nn.LSTM(\n",
    "            input_size=embedding_dim,\n",
    "            hidden_size=hidden_size,\n",
    "            num_layers=2,\n",
    "            dropout=0.5,\n",
    "            batch_first=True,\n",
    "            bidirectional=True\n",
    "        )\n",
    "\n",
    "        self.attention = AttentionMechanism(hidden_size * 2)\n",
    "\n",
    "        self.dropout = torch.nn.Dropout(0.5)\n",
    "\n",
    "        self.fc = torch.nn.Linear(hidden_size * 2, output_size)\n",
    "        \n",
    "        self.batch_norm = torch.nn.BatchNorm1d(output_size)\n",
    "\n",
    "    def forward(self, x: torch.Tensor, /) -> torch.Tensor:\n",
    "        embedded = self.dropout(self.embedding(x))\n",
    "        lstm_out, _ = self.lstm(embedded)\n",
    "        attn_out = self.attention(lstm_out)\n",
    "        out = self.fc(self.dropout(attn_out))\n",
    "        return self.batch_norm(out)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Define LSTM model training and evaluation functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_accuracy(predictions: torch.Tensor, labels: torch.Tensor) -> float:\n",
    "    _, predicted_labels = torch.max(predictions, dim=1)\n",
    "    correct = (predicted_labels == labels).float()\n",
    "    accuracy = correct.sum() / len(correct)\n",
    "    return accuracy.item()\n",
    "\n",
    "\n",
    "def process_epoch(\n",
    "    dataset_loader: DataLoader,\n",
    "    model: SentimentLSTMModel,\n",
    "    optimizer: torch.optim.Optimizer,\n",
    "    criterion: torch.nn.Module,\n",
    "    is_training: bool = True\n",
    ") -> tuple[float, float]:\n",
    "\n",
    "    if is_training:\n",
    "        model.train()\n",
    "    else:\n",
    "        model.eval()\n",
    "\n",
    "    total_loss, total_accuracy, batch_count = 0.0, 0.0, 0\n",
    "    for inputs, labels in dataset_loader:\n",
    "        inputs, labels = inputs.to(device), labels.to(device)\n",
    "\n",
    "        with torch.set_grad_enabled(is_training):\n",
    "            predictions = model(inputs)\n",
    "            loss = criterion(predictions, labels)\n",
    "            if is_training:\n",
    "                optimizer.zero_grad(set_to_none=True)\n",
    "                loss.backward()\n",
    "                optimizer.step()\n",
    "\n",
    "        total_loss += loss.item()\n",
    "        total_accuracy += calculate_accuracy(predictions, labels)\n",
    "        batch_count += 1\n",
    "\n",
    "    avg_loss = total_loss / batch_count\n",
    "    avg_accuracy = total_accuracy / batch_count\n",
    "    return avg_loss, avg_accuracy\n",
    "\n",
    "\n",
    "def run_training_loop(\n",
    "    model: SentimentLSTMModel,\n",
    "    train_loader: DataLoader,\n",
    "    valid_loader: DataLoader,\n",
    "    optimizer: torch.optim.Optimizer,\n",
    "    criterion: torch.nn.Module,\n",
    "    n_epochs: int,\n",
    "    early_stopping_patience: int\n",
    ") -> None:\n",
    "    best_valid_loss = float('inf')\n",
    "    patience_counter = 0\n",
    "\n",
    "    for epoch in range(n_epochs):\n",
    "        train_loss, train_accuracy = process_epoch(\n",
    "            train_loader,\n",
    "            model,\n",
    "            optimizer,\n",
    "            criterion,\n",
    "            is_training=True\n",
    "        )\n",
    "        valid_loss, valid_accuracy = process_epoch(\n",
    "            valid_loader,\n",
    "            model,\n",
    "            optimizer,\n",
    "            criterion,\n",
    "            is_training=False\n",
    "        )\n",
    "\n",
    "        if valid_loss < best_valid_loss:\n",
    "            best_valid_loss = valid_loss\n",
    "            patience_counter = 0\n",
    "            torch.save(model.state_dict(), 'best_lstm_model.pt')\n",
    "        else:\n",
    "            patience_counter += 1\n",
    "            if patience_counter >= early_stopping_patience:\n",
    "                print(\"Early stopping triggered.\")\n",
    "                break\n",
    "\n",
    "        print(\n",
    "            f'Epoch {epoch + 1}/{n_epochs} '\n",
    "            f'- Train Loss: {train_loss:.4f}, '\n",
    "            f'Train Accuracy: {train_accuracy:.4f}, '\n",
    "            f'Valid Loss: {valid_loss:.4f}, '\n",
    "            f'Valid Accuracy: {valid_accuracy:.4f}'\n",
    "        )\n",
    "\n",
    "\n",
    "def train_torch_model(\n",
    "    model: torch.nn.Module,\n",
    "    train_loader: DataLoader,\n",
    "    loss_fn: torch.nn.Module,\n",
    "    optimizer: torch.optim.Optimizer,\n",
    ") -> float:\n",
    "    \"\"\"Train the model for one epoch.\n",
    "\n",
    "    Args:\n",
    "        model: The neural network model.\n",
    "        train_loader: DataLoader for the training dataset.\n",
    "        loss_fn: The loss function.\n",
    "        optimizer: The optimizer.\n",
    "        device: The device to run the training on.\n",
    "\n",
    "    Returns:\n",
    "        The average loss for this training epoch.\n",
    "    \"\"\"\n",
    "    model.train()\n",
    "    total_loss = 0.0\n",
    "\n",
    "    for tweets, sentiments in train_loader:\n",
    "        optimizer.zero_grad(set_to_none=True)\n",
    "        with torch.set_grad_enabled(True), torch.cuda.amp.autocast():\n",
    "            outputs = model(tweets)\n",
    "            loss = loss_fn(outputs, sentiments)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        total_loss += loss.item()\n",
    "\n",
    "    average_loss = total_loss / len(train_loader)\n",
    "    return average_loss\n",
    "\n",
    "\n",
    "def evaluate_torch_model(\n",
    "    model: torch.nn.Module,\n",
    "    val_loader: DataLoader,\n",
    "    loss_fn: torch.nn.Module,\n",
    ") -> tuple[float, float]:\n",
    "    \"\"\"Evaluate the model performance on the validation set.\n",
    "\n",
    "    Args:\n",
    "        model: The neural network model.\n",
    "        val_loader: DataLoader for the validation dataset.\n",
    "        device: The device to run the evaluation on.\n",
    "\n",
    "    Returns:\n",
    "        A tuple of accuracy and the average loss on the validation set.\n",
    "    \"\"\"\n",
    "    model.eval()\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    total_loss = 0.0\n",
    "\n",
    "    for tweets, sentiments in val_loader:\n",
    "        with torch.no_grad(), torch.cuda.amp.autocast():\n",
    "            outputs = model(tweets)\n",
    "            loss = loss_fn(outputs, sentiments)\n",
    "        total_loss += loss.item()\n",
    "        _, predicted = torch.max(outputs.data, 1)\n",
    "        total += sentiments.size(0)\n",
    "        correct += (predicted == sentiments).sum().item()\n",
    "\n",
    "    accuracy = correct / total\n",
    "    average_loss = total_loss / len(val_loader)\n",
    "    return accuracy, average_loss"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Get GloVe Embedding vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "glove_word_indexes: Optional[dict[str, int]] = global_cache.get(\"glove_word_indexes\")\n",
    "glove_word_vectors: Optional[np.ndarray] = global_cache.get(\"glove_word_vectors\")\n",
    "\n",
    "if (glove_word_indexes is None) or (glove_word_vectors is None):\n",
    "    glove_prepare_task.wait()\n",
    "    glove_word_indexes, glove_word_vectors = parse_glove_data(target_glove_file_name)\n",
    "\n",
    "    try:\n",
    "        global_cache.put(\"glove_word_indexes\", glove_word_indexes)\n",
    "        global_cache.put(\"glove_word_vectors\", glove_word_vectors)\n",
    "    except Exception as e:\n",
    "        print(e)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Setup the model, loss function, and optimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training set tokens not in GloVe: 8298\n",
      "45101\n",
      "SentimentLSTMModel(\n",
      "  (embedding): Embedding(400002, 100, padding_idx=0)\n",
      "  (lstm): LSTM(100, 256, num_layers=2, batch_first=True, dropout=0.5, bidirectional=True)\n",
      "  (attention): AttentionMechanism()\n",
      "  (dropout): Dropout(p=0.5, inplace=False)\n",
      "  (fc): Linear(in_features=512, out_features=3, bias=True)\n",
      "  (batch_norm): BatchNorm1d(3, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "assert glove_word_indexes is not None\n",
    "assert glove_word_vectors is not None\n",
    "\n",
    "glove_vectorizer = GloVeVectorizer(glove_word_indexes, glove_word_vectors)\n",
    "\n",
    "training_glove_indexes = glove_vectorizer.ordinalization(\n",
    "    cleaned_training_tweets\n",
    ")\n",
    "\n",
    "# Calculate how many tokens in the training set are not in the GloVe word vectors.\n",
    "training_glove_tokens = np.count_nonzero(training_glove_indexes == 400001)\n",
    "print(f\"Training set tokens not in GloVe: {training_glove_tokens}\")\n",
    "print(len(training_glove_indexes))\n",
    "\n",
    "dev_glove_indexes = glove_vectorizer.ordinalization(cleaned_dev_tweets)\n",
    "\n",
    "test_glove_indexs = [\n",
    "    glove_vectorizer.ordinalization(test_data)\n",
    "    for test_data in cleaned_test_tweets\n",
    "]\n",
    "\n",
    "training_dataset = TensorDataset(\n",
    "    torch.from_numpy(training_glove_indexes).to_dense().to(device),\n",
    "    torch.tensor(\n",
    "        [sentiments.value for sentiments in training_sentiments]\n",
    "    ).to_dense().to(device)\n",
    ")\n",
    "dev_dataset = TensorDataset(\n",
    "    torch.from_numpy(dev_glove_indexes).to_dense().to(device),\n",
    "    torch.tensor(\n",
    "        [sentiments.value for sentiments in dev_sentiments]\n",
    "    ).to_dense().to(device)\n",
    ")\n",
    "test_datasets = [\n",
    "    TensorDataset(\n",
    "        torch.from_numpy(test_glove_index).to_dense().to(device),\n",
    "        torch.tensor(\n",
    "            [sentiments.value for sentiments in test_sentiments]\n",
    "        ).to_dense().to(device)\n",
    "    )\n",
    "    for test_glove_index, test_sentiments in zip(\n",
    "        test_glove_indexs,\n",
    "        test_sentiments\n",
    "    )\n",
    "]\n",
    "\n",
    "lstm_model = SentimentLSTMModel(\n",
    "    embedding_dim=glove_word_vectors.shape[1],\n",
    "    hidden_size=256,\n",
    "    output_size=len(Sentiment.gts()),\n",
    "    pretrained_embeddings=torch.from_numpy(glove_word_vectors).float()\n",
    ").to(device)\n",
    "\n",
    "lstm_loss_fn = torch.nn.CrossEntropyLoss(\n",
    "    ignore_index=400001\n",
    ").to(device)\n",
    "lstm_optimizer = torch.optim.AdamW(\n",
    "    lstm_model.parameters(),\n",
    "    lr=1e-2,\n",
    "    weight_decay=1e-4\n",
    ")\n",
    "\n",
    "print(lstm_model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### train the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20, Train Loss: 0.93655, Dev Loss: 0.85045, Dev Accuracy: 0.60150\n",
      "Epoch 2/20, Train Loss: 0.84788, Dev Loss: 0.77900, Dev Accuracy: 0.63200\n",
      "Epoch 3/20, Train Loss: 0.82878, Dev Loss: 0.75911, Dev Accuracy: 0.64850\n",
      "Epoch 4/20, Train Loss: 0.81021, Dev Loss: 0.75249, Dev Accuracy: 0.64600\n",
      "Epoch 5/20, Train Loss: 0.79623, Dev Loss: 0.73259, Dev Accuracy: 0.65950\n",
      "Epoch 6/20, Train Loss: 0.78665, Dev Loss: 0.73459, Dev Accuracy: 0.66600\n",
      "Epoch 7/20, Train Loss: 0.77795, Dev Loss: 0.72510, Dev Accuracy: 0.66850\n",
      "Epoch 8/20, Train Loss: 0.77262, Dev Loss: 0.73088, Dev Accuracy: 0.65800\n",
      "Epoch 9/20, Train Loss: 0.77104, Dev Loss: 0.72714, Dev Accuracy: 0.66950\n",
      "Epoch 10/20, Train Loss: 0.76195, Dev Loss: 0.72265, Dev Accuracy: 0.66450\n",
      "Epoch 11/20, Train Loss: 0.75909, Dev Loss: 0.72807, Dev Accuracy: 0.67300\n",
      "Epoch 12/20, Train Loss: 0.75556, Dev Loss: 0.73383, Dev Accuracy: 0.66650\n",
      "Epoch 13/20, Train Loss: 0.75062, Dev Loss: 0.71130, Dev Accuracy: 0.67850\n",
      "Epoch 14/20, Train Loss: 0.74488, Dev Loss: 0.72282, Dev Accuracy: 0.66500\n",
      "Epoch 15/20, Train Loss: 0.74218, Dev Loss: 0.71185, Dev Accuracy: 0.67950\n",
      "Epoch 16/20, Train Loss: 0.74652, Dev Loss: 0.71499, Dev Accuracy: 0.68150\n",
      "Epoch 17/20, Train Loss: 0.74836, Dev Loss: 0.72002, Dev Accuracy: 0.67850\n",
      "Epoch 18/20, Train Loss: 0.74377, Dev Loss: 0.71179, Dev Accuracy: 0.68450\n",
      "Epoch 19/20, Train Loss: 0.74595, Dev Loss: 0.71387, Dev Accuracy: 0.67900\n",
      "Epoch 20/20, Train Loss: 0.74554, Dev Loss: 0.70972, Dev Accuracy: 0.68300\n",
      "Test 1 Accuracy: 0.68479\n",
      "Test 2 Accuracy: 0.68591\n",
      "Test 3 Accuracy: 0.64103\n"
     ]
    }
   ],
   "source": [
    "epochs = 20\n",
    "batch_size = 512\n",
    "workers = cpu_count() or 1\n",
    "\n",
    "training_loader = DataLoader(\n",
    "    training_dataset,\n",
    "    batch_size=batch_size,\n",
    "    shuffle=True,\n",
    ")\n",
    "dev_loader = DataLoader(\n",
    "    dev_dataset,\n",
    "    batch_size=batch_size,\n",
    "    shuffle=False,\n",
    ")\n",
    "test_loaders = [\n",
    "    DataLoader(\n",
    "        test_dataset,\n",
    "        batch_size=batch_size,\n",
    "        shuffle=False,\n",
    "    )\n",
    "    for test_dataset in test_datasets\n",
    "]\n",
    "torch.jit.enable_onednn_fusion(True)\n",
    "torch.backends.cudnn.benchmark = True\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    train_loss = train_torch_model(\n",
    "        lstm_model,\n",
    "        training_loader,\n",
    "        lstm_loss_fn,\n",
    "        lstm_optimizer\n",
    "    )\n",
    "    dev_accuracy, dev_loss = evaluate_torch_model(\n",
    "        lstm_model,\n",
    "        dev_loader,\n",
    "        lstm_loss_fn\n",
    "    )\n",
    "    print(\n",
    "        f\"Epoch {epoch+1}/{epochs}, Train Loss: {train_loss:.5f}, \"\n",
    "        f\"Dev Loss: {dev_loss:.5f}, Dev Accuracy: {dev_accuracy:.5f}\"\n",
    "    )\n",
    "\n",
    "test_accuracies = [\n",
    "    evaluate_torch_model(\n",
    "        lstm_model,\n",
    "        test_loader,\n",
    "        lstm_loss_fn\n",
    "    )\n",
    "    for test_loader in test_loaders\n",
    "]\n",
    "\n",
    "for i, (test_accuracy, _) in enumerate(test_accuracies):\n",
    "    print(f\"Test {i+1} Accuracy: {test_accuracy:.5f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### BERT Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "bert_prepare_task.wait()\n",
    "\n",
    "bert_tokenizer: BertTokenizer = BertTokenizer.from_pretrained(\n",
    "    target_bert_model_name)\n",
    "\n",
    "bert_model_pretrained: BertModel = BertModel.from_pretrained(\n",
    "    target_bert_model_name\n",
    ")  # type: ignore"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_bert() -> tuple[TensorDataset, TensorDataset, list[TensorDataset]]:\n",
    "    training_bert = bert_tokenizer(\n",
    "        list(cleaned_training_tweets.values()),\n",
    "        padding=True,\n",
    "        truncation=True,\n",
    "        return_tensors=\"pt\"\n",
    "    )\n",
    "    dev_bert = bert_tokenizer(\n",
    "        list(cleaned_dev_tweets.values()),\n",
    "        padding=True,\n",
    "        truncation=True,\n",
    "        return_tensors=\"pt\"\n",
    "    )\n",
    "    test_berts = [\n",
    "        bert_tokenizer(\n",
    "            list(test_data.values()),\n",
    "            padding=True,\n",
    "            truncation=True,\n",
    "            return_tensors=\"pt\"\n",
    "        )\n",
    "        for test_data in cleaned_test_tweets\n",
    "    ]\n",
    "\n",
    "    training_bert_dataset = TensorDataset(\n",
    "        training_bert.input_ids.to_dense().to(device),\n",
    "        training_bert.attention_mask.to_dense().to(device),\n",
    "        torch.tensor(\n",
    "            [sentiments.value for sentiments in training_sentiments]\n",
    "        ).to_dense().to(device)\n",
    "    )\n",
    "    dev_bert_dataset = TensorDataset(\n",
    "        dev_bert.input_ids.to_dense().to(device),\n",
    "        dev_bert.attention_mask.to_dense().to(device),\n",
    "        torch.tensor(\n",
    "            [sentiments.value for sentiments in dev_sentiments]\n",
    "        ).to_dense().to(device)\n",
    "    )\n",
    "    test_bert_datasets = [\n",
    "        TensorDataset(\n",
    "            test_bert.input_ids.to_dense().to(device),\n",
    "            test_bert.attention_mask.to_dense().to(device),\n",
    "            torch.tensor(\n",
    "                [sentiments.value for sentiments in test_sentiments]\n",
    "            ).to_dense().to(device)\n",
    "        )\n",
    "        for test_bert, test_sentiments in zip(\n",
    "            test_berts,\n",
    "            test_sentiments\n",
    "        )\n",
    "    ]\n",
    "\n",
    "    return training_bert_dataset, dev_bert_dataset, test_bert_datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SentimentBERTModel(torch.nn.Module):\n",
    "    def __init__(self, freeze: bool = False, config: BertConfig = BertConfig()):\n",
    "        super(SentimentBERTModel, self).__init__()\n",
    "        label_count = len(Sentiment.gts())\n",
    "        custom_hidden_size = 256\n",
    "        self.bert = bert_model_pretrained\n",
    "        self.dropout = torch.nn.Dropout(config.hidden_dropout_prob)\n",
    "        self.classifier = torch.nn.Sequential(\n",
    "            torch.nn.Linear(config.hidden_size, custom_hidden_size),\n",
    "            torch.nn.ReLU(),\n",
    "            torch.nn.Linear(custom_hidden_size, label_count),\n",
    "            torch.nn.Dropout(config.hidden_dropout_prob),\n",
    "            torch.nn.BatchNorm1d(label_count)\n",
    "        )\n",
    "\n",
    "        if freeze:\n",
    "            for param in self.bert.parameters():\n",
    "                param.requires_grad = False\n",
    "\n",
    "    def forward(\n",
    "        self,\n",
    "        input_ids: torch.Tensor,\n",
    "        attention_mask: Optional[torch.Tensor] = None,\n",
    "    ) -> torch.Tensor:\n",
    "        outputs = self.bert(input_ids=input_ids, attention_mask=attention_mask)\n",
    "        last_hidden_state_cls = outputs.last_hidden_state[:, 0, :]\n",
    "        pooled_output = self.dropout(last_hidden_state_cls)\n",
    "        logits = self.classifier(pooled_output)\n",
    "        return logits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "def bert_train(\n",
    "    model: torch.nn.Module,\n",
    "    train_loader: DataLoader,\n",
    "    optimizer: torch.optim.Optimizer,\n",
    "    scheduler: torch.optim.lr_scheduler.LambdaLR,\n",
    "    loss_fn: torch.nn.Module,\n",
    ") -> float:\n",
    "    model.train()\n",
    "    total_loss = 0.0\n",
    "    for batch in tqdm(train_loader, desc=\"Bert Training\"):\n",
    "        batch = [item for item in batch]\n",
    "        inputs = {\n",
    "            'input_ids': batch[0],\n",
    "            'attention_mask': batch[1],\n",
    "        }\n",
    "        labels = batch[2]\n",
    "\n",
    "        optimizer.zero_grad(set_to_none=True)\n",
    "\n",
    "        with torch.set_grad_enabled(True), torch.cuda.amp.autocast():\n",
    "            outputs = model(**inputs)\n",
    "            loss = loss_fn(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        scheduler.step()\n",
    "\n",
    "        total_loss += loss.item()\n",
    "\n",
    "    average_loss = total_loss / len(train_loader)\n",
    "    return average_loss\n",
    "\n",
    "\n",
    "def bert_evaluate(\n",
    "    model: torch.nn.Module,\n",
    "    validation_loader: DataLoader,\n",
    "    loss_fn: torch.nn.Module,\n",
    ") -> tuple[float, float]:\n",
    "    model.eval()\n",
    "    total_loss = 0.0\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    \n",
    "    with torch.no_grad(), torch.cuda.amp.autocast():\n",
    "        for batch in tqdm(validation_loader, desc=\"Bert Evaluating\"):\n",
    "            batch = [item for item in batch]\n",
    "            inputs = {\n",
    "                'input_ids': batch[0],\n",
    "                'attention_mask': batch[1],\n",
    "            }\n",
    "            labels = batch[2]\n",
    "\n",
    "            outputs = model(**inputs)\n",
    "            loss = loss_fn(outputs, labels)\n",
    "            total_loss += loss.item()\n",
    "            correct += (torch.argmax(outputs, dim=1) == labels).sum().item()\n",
    "            total += labels.size(0)\n",
    "\n",
    "    average_loss = total_loss / len(validation_loader)\n",
    "    accuracy = correct / total\n",
    "    return average_loss, accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SentimentBERTModel(\n",
      "  (bert): BertModel(\n",
      "    (embeddings): BertEmbeddings(\n",
      "      (word_embeddings): Embedding(105879, 768, padding_idx=0)\n",
      "      (position_embeddings): Embedding(512, 768)\n",
      "      (token_type_embeddings): Embedding(2, 768)\n",
      "      (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "      (dropout): Dropout(p=0.1, inplace=False)\n",
      "    )\n",
      "    (encoder): BertEncoder(\n",
      "      (layer): ModuleList(\n",
      "        (0-11): 12 x BertLayer(\n",
      "          (attention): BertAttention(\n",
      "            (self): BertSelfAttention(\n",
      "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "            (output): BertSelfOutput(\n",
      "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "          )\n",
      "          (intermediate): BertIntermediate(\n",
      "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
      "            (intermediate_act_fn): GELUActivation()\n",
      "          )\n",
      "          (output): BertOutput(\n",
      "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
      "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (pooler): BertPooler(\n",
      "      (dense): Linear(in_features=768, out_features=768, bias=True)\n",
      "      (activation): Tanh()\n",
      "    )\n",
      "  )\n",
      "  (dropout): Dropout(p=0.1, inplace=False)\n",
      "  (classifier): Sequential(\n",
      "    (0): Linear(in_features=768, out_features=256, bias=True)\n",
      "    (1): ReLU()\n",
      "    (2): Linear(in_features=256, out_features=3, bias=True)\n",
      "    (3): Dropout(p=0.1, inplace=False)\n",
      "    (4): BatchNorm1d(3, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  )\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "epochs = 20\n",
    "batch_size = 32\n",
    "\n",
    "bert_model = SentimentBERTModel(freeze=True).to(device)\n",
    "bert_optimizer = torch.optim.AdamW(bert_model.parameters(), lr=2e-5)\n",
    "bert_looser = torch.nn.CrossEntropyLoss().to(device)\n",
    "\n",
    "print(bert_model)\n",
    "\n",
    "total_steps = len(cleaned_training_tweets) * epochs\n",
    "bert_scheduler = get_linear_schedule_with_warmup(\n",
    "    bert_optimizer,\n",
    "    num_warmup_steps=0,\n",
    "    num_training_steps=total_steps\n",
    ")\n",
    "\n",
    "training_bert_dataset, dev_bert_dataset, test_bert_datasets = preprocess_bert()\n",
    "\n",
    "training_bert_loader = DataLoader(\n",
    "    training_bert_dataset,\n",
    "    batch_size=batch_size,\n",
    "    shuffle=True\n",
    ")\n",
    "dev_bert_loader = DataLoader(\n",
    "    dev_bert_dataset,\n",
    "    batch_size=batch_size,\n",
    "    shuffle=False\n",
    ")\n",
    "test_bert_loaders = [\n",
    "    DataLoader(\n",
    "        test_bert_dataset,\n",
    "        batch_size=batch_size,\n",
    "        shuffle=False\n",
    "    )\n",
    "    for test_bert_dataset in test_bert_datasets\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Bert Training: 100%|██████████| 1410/1410 [01:19<00:00, 17.74it/s]\n",
      "Bert Evaluating: 100%|██████████| 63/63 [00:05<00:00, 12.29it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20, Train Loss: 1.11937, Dev Loss: 0.96240, Dev Accuracy: 0.53550\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Bert Training: 100%|██████████| 1410/1410 [01:21<00:00, 17.27it/s]\n",
      "Bert Evaluating: 100%|██████████| 63/63 [00:05<00:00, 12.29it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2/20, Train Loss: 1.02891, Dev Loss: 0.94133, Dev Accuracy: 0.53550\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Bert Training: 100%|██████████| 1410/1410 [01:21<00:00, 17.26it/s]\n",
      "Bert Evaluating: 100%|██████████| 63/63 [00:05<00:00, 12.29it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3/20, Train Loss: 1.00876, Dev Loss: 0.93975, Dev Accuracy: 0.53900\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Bert Training: 100%|██████████| 1410/1410 [01:21<00:00, 17.26it/s]\n",
      "Bert Evaluating: 100%|██████████| 63/63 [00:05<00:00, 12.29it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4/20, Train Loss: 0.99448, Dev Loss: 0.93596, Dev Accuracy: 0.55050\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Bert Training: 100%|██████████| 1410/1410 [01:21<00:00, 17.25it/s]\n",
      "Bert Evaluating: 100%|██████████| 63/63 [00:05<00:00, 12.29it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5/20, Train Loss: 0.98747, Dev Loss: 0.91360, Dev Accuracy: 0.55500\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Bert Training: 100%|██████████| 1410/1410 [01:21<00:00, 17.25it/s]\n",
      "Bert Evaluating: 100%|██████████| 63/63 [00:05<00:00, 12.29it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 6/20, Train Loss: 0.97815, Dev Loss: 0.89665, Dev Accuracy: 0.57950\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Bert Training: 100%|██████████| 1410/1410 [01:21<00:00, 17.25it/s]\n",
      "Bert Evaluating: 100%|██████████| 63/63 [00:05<00:00, 12.29it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 7/20, Train Loss: 0.97189, Dev Loss: 0.90067, Dev Accuracy: 0.56000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Bert Training: 100%|██████████| 1410/1410 [01:21<00:00, 17.25it/s]\n",
      "Bert Evaluating: 100%|██████████| 63/63 [00:05<00:00, 12.29it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 8/20, Train Loss: 0.96291, Dev Loss: 0.88619, Dev Accuracy: 0.58100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Bert Training: 100%|██████████| 1410/1410 [01:21<00:00, 17.24it/s]\n",
      "Bert Evaluating: 100%|██████████| 63/63 [00:05<00:00, 12.29it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9/20, Train Loss: 0.95903, Dev Loss: 0.90733, Dev Accuracy: 0.55700\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Bert Training: 100%|██████████| 1410/1410 [01:21<00:00, 17.25it/s]\n",
      "Bert Evaluating: 100%|██████████| 63/63 [00:05<00:00, 12.29it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 10/20, Train Loss: 0.95434, Dev Loss: 0.89884, Dev Accuracy: 0.56450\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Bert Training: 100%|██████████| 1410/1410 [01:21<00:00, 17.24it/s]\n",
      "Bert Evaluating: 100%|██████████| 63/63 [00:05<00:00, 12.29it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 11/20, Train Loss: 0.94655, Dev Loss: 0.87950, Dev Accuracy: 0.58750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Bert Training: 100%|██████████| 1410/1410 [01:21<00:00, 17.23it/s]\n",
      "Bert Evaluating: 100%|██████████| 63/63 [00:05<00:00, 12.29it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 12/20, Train Loss: 0.94839, Dev Loss: 0.88305, Dev Accuracy: 0.58300\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Bert Training: 100%|██████████| 1410/1410 [01:21<00:00, 17.23it/s]\n",
      "Bert Evaluating: 100%|██████████| 63/63 [00:05<00:00, 12.28it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 13/20, Train Loss: 0.93863, Dev Loss: 0.88554, Dev Accuracy: 0.57650\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Bert Training: 100%|██████████| 1410/1410 [01:21<00:00, 17.23it/s]\n",
      "Bert Evaluating: 100%|██████████| 63/63 [00:05<00:00, 12.28it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 14/20, Train Loss: 0.93705, Dev Loss: 0.87803, Dev Accuracy: 0.57500\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Bert Training: 100%|██████████| 1410/1410 [01:21<00:00, 17.22it/s]\n",
      "Bert Evaluating: 100%|██████████| 63/63 [00:05<00:00, 12.29it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 15/20, Train Loss: 0.93646, Dev Loss: 0.87726, Dev Accuracy: 0.58550\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Bert Training: 100%|██████████| 1410/1410 [01:21<00:00, 17.23it/s]\n",
      "Bert Evaluating: 100%|██████████| 63/63 [00:05<00:00, 12.29it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 16/20, Train Loss: 0.93162, Dev Loss: 0.87599, Dev Accuracy: 0.57350\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Bert Training: 100%|██████████| 1410/1410 [01:21<00:00, 17.24it/s]\n",
      "Bert Evaluating: 100%|██████████| 63/63 [00:05<00:00, 12.29it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 17/20, Train Loss: 0.93038, Dev Loss: 0.88928, Dev Accuracy: 0.57500\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Bert Training: 100%|██████████| 1410/1410 [01:21<00:00, 17.23it/s]\n",
      "Bert Evaluating: 100%|██████████| 63/63 [00:05<00:00, 12.29it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 18/20, Train Loss: 0.92698, Dev Loss: 0.87322, Dev Accuracy: 0.58250\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Bert Training: 100%|██████████| 1410/1410 [01:21<00:00, 17.23it/s]\n",
      "Bert Evaluating: 100%|██████████| 63/63 [00:05<00:00, 12.29it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 19/20, Train Loss: 0.92501, Dev Loss: 0.87616, Dev Accuracy: 0.57550\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Bert Training: 100%|██████████| 1410/1410 [01:21<00:00, 17.23it/s]\n",
      "Bert Evaluating: 100%|██████████| 63/63 [00:05<00:00, 12.29it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 20/20, Train Loss: 0.92256, Dev Loss: 0.86651, Dev Accuracy: 0.58250\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Bert Evaluating: 100%|██████████| 111/111 [00:06<00:00, 17.95it/s]\n",
      "Bert Evaluating: 100%|██████████| 58/58 [00:02<00:00, 23.13it/s]\n",
      "Bert Evaluating: 100%|██████████| 75/75 [00:03<00:00, 23.36it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test 1 Loss: 0.85966, Test 1 Accuracy: 0.59615\n",
      "Test 2 Loss: 0.82451, Test 2 Accuracy: 0.60982\n",
      "Test 3 Loss: 0.87440, Test 3 Accuracy: 0.58806\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(epochs):\n",
    "    bert_train_loss = bert_train(\n",
    "        bert_model,\n",
    "        training_bert_loader,\n",
    "        bert_optimizer,\n",
    "        bert_scheduler,\n",
    "        bert_looser\n",
    "    )\n",
    "    bert_dev_loss, bert_dev_accuracy = bert_evaluate(\n",
    "        bert_model,\n",
    "        dev_bert_loader,\n",
    "        bert_looser\n",
    "    )\n",
    "    print(\n",
    "        f\"Epoch {epoch+1}/{epochs}, Train Loss: {bert_train_loss:.5f}, \"\n",
    "        f\"Dev Loss: {bert_dev_loss:.5f}, \"\n",
    "        f\"Dev Accuracy: {bert_dev_accuracy:.5f}\"\n",
    "    )\n",
    "\n",
    "bert_test_results = [\n",
    "    bert_evaluate(\n",
    "        bert_model,\n",
    "        test_bert_loader,\n",
    "        bert_looser\n",
    "    )\n",
    "    for test_bert_loader in test_bert_loaders\n",
    "]\n",
    "\n",
    "for i, (test_loss, test_accuracy) in enumerate(bert_test_results):\n",
    "    print(f\"Test {i+1} Loss: {test_loss:.5f}, Test {i+1} Accuracy: {test_accuracy:.5f}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
